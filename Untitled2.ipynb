{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'torch'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'yHatMat'\n",
    "require 'mixtureCriterionMat'\n",
    "require 'windowMat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = nn.YHat()\n",
    "mix = nn.MixtureCriterion()\n",
    "wind = nn.Window()\n",
    "w_y = nn.Linear(83,121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tar = torch.Tensor({{0.5,0.5,1},{0.5,0.5,1}})\n",
    "yhat:settarget(tar)\n",
    "\n",
    "function feval(x)   \n",
    "    dl = yhat:backward(x:t())\n",
    "    --print(dl)\n",
    "    out = yhat:forward(x:t())\n",
    "    l = mix:forward(out, tar)/2.0\n",
    "    --print(l)\n",
    "    return l, (dl:t()):double()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat:setmask(torch.ones(1,121))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind:setmask(torch.ones(1,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff,q,e = optim.checkgrad(feval, torch.Tensor(121,2):fill(0.8),10^-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix:setmask(torch.ones(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0492165188049e-06\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.6900  0.6900\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0000  0.0000\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0018  0.0018\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       " 0.0495  0.0495\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "-0.0334 -0.0334\n",
       "[torch.DoubleTensor of size 121x2]\n",
       "\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 6.8997e-01  6.8997e-01\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.3878e-17  1.3878e-17\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 1.8199e-03  1.8199e-03\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       " 4.9454e-02  4.9454e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "-3.3385e-02 -3.3385e-02\n",
       "[torch.DoubleTensor of size 121x2]\n",
       "\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'parsevocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kappa_prev = torch.randn(1,10)\n",
    "kappa_next = torch.zeros(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cu = getOneHotStrs({[1]=\"cats are not good\",[2]=\"mats are not good\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  1\n",
       " 17\n",
       " 83\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind:setcu(cu)\n",
    "wind:setKappaPrev(kappa_prev)\n",
    "wind:setGradKappaNext(kappa_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tar = torch.Tensor({{0.5,0.5,1}})\n",
    "yhat:settarget(tar)\n",
    "\n",
    "function feval(x)   \n",
    "    \n",
    "    --forward\n",
    "    out_w = wind:forward(x:t())\n",
    "    out_w_y = w_y:forward(out_w)\n",
    "    out_y = yhat:forward(out_w_y)\n",
    "    l = mix:forward(out_y, tar)\n",
    "    \n",
    "    --backward\n",
    "    dl_y = yhat:backward(out_w_y)\n",
    "    dl_w_y = w_y:backward(out_w, dl_y)\n",
    "    dl = wind:backward(x:t(), dl_w_y)\n",
    "    dl:resize(1,30)\n",
    "    --print(dl)\n",
    "    \n",
    "    return l, (dl:sum(1):expand(1,30):t():double())\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff,q,e = optim.checkgrad(feval, torch.Tensor(30,1):fill(0.8),10^-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.610549278792e-05\t\n"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0044\n",
       " 0.1706\n",
       " 0.0877\n",
       " 0.1368\n",
       " 0.1515\n",
       " 0.1857\n",
       " 0.1435\n",
       " 0.1809\n",
       " 0.1855\n",
       " 0.1548\n",
       "-0.0329\n",
       "-0.0947\n",
       "-0.0641\n",
       "-0.0437\n",
       "-0.0779\n",
       "-0.0224\n",
       "-0.0592\n",
       "-0.0846\n",
       "-0.0768\n",
       "-0.0846\n",
       "-0.0805\n",
       " 0.1929\n",
       "-0.5381\n",
       "-0.5333\n",
       " 0.1409\n",
       "-0.2708\n",
       " 0.1535\n",
       " 0.1991\n",
       " 0.1878\n",
       " 0.1457\n",
       "[torch.DoubleTensor of size 30x1]\n",
       "\n"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0044\n",
       " 0.1706\n",
       " 0.0877\n",
       " 0.1368\n",
       " 0.1516\n",
       " 0.1857\n",
       " 0.1436\n",
       " 0.1809\n",
       " 0.1856\n",
       " 0.1548\n",
       "-0.0330\n",
       "-0.0947\n",
       "-0.0641\n",
       "-0.0437\n",
       "-0.0779\n",
       "-0.0224\n",
       "-0.0592\n",
       "-0.0846\n",
       "-0.0768\n",
       "-0.0847\n",
       "-0.0804\n",
       " 0.1929\n",
       "-0.5383\n",
       "-0.5335\n",
       " 0.1409\n",
       "-0.2709\n",
       " 0.1535\n",
       " 0.1990\n",
       " 0.1877\n",
       " 0.1456\n",
       "[torch.DoubleTensor of size 30x1]\n",
       "\n"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  1\n",
       " 17\n",
       " 83\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 26\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
       "\n",
       "Columns 27 to 52\n",
       " 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "Columns 53 to 78\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "Columns 79 to 83\n",
       " 0  0  0  0  0\n",
       " 0  0  0  0  0\n",
       "[torch.DoubleTensor of size 2x83]\n",
       "\n"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu[{{},{1},{}}]:squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
